{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLz22auKPF2w"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***SVM Classifier Without Any Explicit Feature Extraction***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eq3gzmGQq3w"
      },
      "source": [
        "### ***1. Importing the libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "5R0IlRRVQywY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9-IOYhwQ4dF"
      },
      "source": [
        "### ***2. Loading and exploring the dataset for a better understanding.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHIw7_waRAM_",
        "outputId": "7c83081a-314e-4a86-c614-732ae420a2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training Data:\n",
            "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
            "0      2       0       0       0       0       0       0       0       0   \n",
            "1      9       0       0       0       0       0       0       0       0   \n",
            "2      6       0       0       0       0       0       0       0       5   \n",
            "3      0       0       0       0       1       2       0       0       0   \n",
            "4      3       0       0       0       0       0       0       0       0   \n",
            "\n",
            "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0       0  ...         0         0         0         0         0         0   \n",
            "1       0  ...         0         0         0         0         0         0   \n",
            "2       0  ...         0         0         0        30        43         0   \n",
            "3       0  ...         3         0         0         0         0         1   \n",
            "4       0  ...         0         0         0         0         0         0   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0         0         0         0         0  \n",
            "1         0         0         0         0  \n",
            "2         0         0         0         0  \n",
            "3         0         0         0         0  \n",
            "4         0         0         0         0  \n",
            "\n",
            "[5 rows x 785 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your dataset\n",
        "dataset_path = '/content/drive/MyDrive/CV Project/Dataset/fashionMNIST-train.csv'\n",
        "\n",
        "# Load Fashion-MNIST training data\n",
        "train_data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Display the first few rows of the training data\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZCL5xaHRRz0"
      },
      "source": [
        "### ***3. Feature extraction.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6Q8tnC_LRVJ6",
        "outputId": "9a5ae665-5ee3-427f-ac30-8f10ce50bfff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extract features (pixel values) and labels for training\n",
        "train_labels = train_data['label'].values[:10000]\n",
        "train_images = train_data.iloc[:10000, 1:].values.reshape(-1, 28, 28)\n",
        "\n",
        "# Display the first few images with their labels\n",
        "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(train_images[i], cmap='gray')\n",
        "    ax.set_title(f\"Label: {train_labels[i]}\")\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_BC0IQReIX"
      },
      "source": [
        "### ***4. Preprocessing the test dataset.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "InxIsZDKRh5S"
      },
      "outputs": [],
      "source": [
        "# Define the path to your dataset\n",
        "test_dataset_path = '/content/drive/MyDrive/CV Project/Dataset/fashionMNIST-test.csv'\n",
        "\n",
        "# Load Fashion-MNIST test data\n",
        "test_data = pd.read_csv(test_dataset_path)\n",
        "\n",
        "# Extract features (pixel values) and labels for testing\n",
        "test_labels = test_data['label'].values\n",
        "test_images = test_data.iloc[:, 1:].values.reshape(-1, 28, 28)  # Use the entire test dataset\n",
        "\n",
        "# Flatten the images for machine learning models\n",
        "test_images_flat = test_images.reshape(test_images.shape[0], -1)\n",
        "\n",
        "# Normalize pixel values to a common scale (e.g., 0 to 1)\n",
        "test_images_scaled = scaler.transform(test_images_flat.astype(float))\n",
        "\n",
        "# Ensure that test_labels has the same size as the number of samples in the test dataset\n",
        "test_labels = test_labels[:len(test_images)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3AhER-1RoK7"
      },
      "source": [
        "### ***5. Flattening the images for both training and testing dataset.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "AGLf-rjRRxWO"
      },
      "outputs": [],
      "source": [
        "# Flatten the images for machine learning models\n",
        "train_images_flat = train_images.reshape(train_images.shape[0], -1)\n",
        "test_images_flat = test_images.reshape(test_images.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrpqWAX3R2r9"
      },
      "source": [
        "### ***6. To bring all the images to a common scale for better and smooth processing.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "uCb6HANDR989"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values to a common scale (e.g., 0 to 1)\n",
        "scaler = StandardScaler()\n",
        "train_images_scaled = scaler.fit_transform(train_images_flat.astype(float))\n",
        "test_images_scaled = scaler.transform(test_images_flat.astype(float))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZjKAHfYSDpf"
      },
      "source": [
        "### ***7. Now splitting the test and train datasets for separate measurements.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "7U6_Up6XSKrB"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "train_images_final, val_images_final, train_labels_final, val_labels_final = \\\n",
        "    train_test_split(train_images_scaled, train_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeTPtfEgSO9z"
      },
      "source": [
        "### ***8. SVM Classifer.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "T-2lp2PVSTL5"
      },
      "outputs": [],
      "source": [
        "# Create an SVM classifier\n",
        "svm_classifier = SVC(C=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YewHuZ7NSVx5"
      },
      "source": [
        "### ***9. Training the model and also measuring the processing time.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMch7NiUSYaU",
        "outputId": "e9436bab-6f56-4bc1-917c-86a50c68e774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 7.49 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training Time\n",
        "start_time = time.time()\n",
        "svm_classifier.fit(train_images_final, train_labels_final)\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9askNF_Se7H"
      },
      "source": [
        "### ***10. Making predictions using our trained model.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg_y2ACQSqqu",
        "outputId": "68020460-25f0-4dea-ef6a-d339bc160ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 85.20%\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the validation set\n",
        "val_predictions = svm_classifier.predict(val_images_final)\n",
        "\n",
        "# Evaluate accuracy on the validation set\n",
        "accuracy = accuracy_score(val_labels_final, val_predictions)\n",
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uT7ytpaThnG"
      },
      "source": [
        "### ***11. Cross Validation.***\n",
        "* 'cross_val_score' is used to perform cross-validation on the SVM model.\n",
        "* 'cv=5' specifies 5-fold cross-validation, dividing the dataset into 5 subsets for training and testing.\n",
        "* 'cross_val_scores' stores the accuracy scores obtained from each fold.\n",
        "* The mean of these scores is calculated to get an overall performance estimate.\n",
        "* The result is printed as cross-validation scores.\n",
        "* I am using a subsample of the data for cross validation since its too large to cross validate the entire dataset. I ran the cross validation on the entire dataset and it took about 25 minutes and still didn't complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av9D8bwWUgMl",
        "outputId": "5357bfa6-53ed-495f-aa45-d3b88ad920eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: 85.74%\n"
          ]
        }
      ],
      "source": [
        "# Subsample data for cross-validation\n",
        "subsample_size = 10000\n",
        "subsample_indices = np.random.choice(len(train_labels), size=subsample_size, replace=False)\n",
        "subsampled_images = train_images_scaled[subsample_indices]\n",
        "subsampled_labels = train_labels[subsample_indices]\n",
        "\n",
        "# Cross-Validation Scores using subsampled data\n",
        "cross_val_scores = cross_val_score(svm_classifier, subsampled_images, subsampled_labels, cv=5, n_jobs=-1)\n",
        "print(f\"Cross-Validation Scores: {np.mean(cross_val_scores) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmjCozUNVkD-"
      },
      "source": [
        "### ***12. Confusion Matrix.***\n",
        "* The confusion matrix is a table that describes the performance of a classification model.\n",
        "* It displays the number of true positive, true negative, false positive, and false negative predictions.\n",
        "* The confusion matrix is printed to analyze how well the SVM model is performing for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd4hgy5TVrU3",
        "outputId": "6a461b80-3361-4e37-f852-9c2dcf67218a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[744   4  27  90   3   0 117   0  14   1]\n",
            " [  7 964   7  18   1   0   3   0   0   0]\n",
            " [ 35   3 680  16 164   0  95   0   7   0]\n",
            " [ 47  33  17 808  54   0  40   0   1   0]\n",
            " [  2   0 120  48 739   0  88   0   3   0]\n",
            " [ 12   1   1   1   1 788   2 116   7  71]\n",
            " [168   7 156  69 133   1 455   0  10   1]\n",
            " [  0   0   0   0   0  61   0 885   0  54]\n",
            " [  6   4  25   9   7   7  34   6 900   2]\n",
            " [  0   0   1   0   0  37   0  64   1 897]]\n"
          ]
        }
      ],
      "source": [
        "test_predictions_subset = best_svm_classifier_large.predict(test_images_scaled[:subset_size_test])\n",
        "\n",
        "# Compute the confusion matrix for the test subset\n",
        "conf_matrix = confusion_matrix(test_labels[:subset_size_test], test_predictions_subset)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4GEEr11VvVJ"
      },
      "source": [
        "### ***13. Classification Report.***\n",
        "* The classification report provides a detailed summary of the model's performance.\n",
        "* It includes precision, recall, F1-score, and support for each class.\n",
        "* The classification report is printed to offer a more granular analysis of the SVM model's capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "fPcB2sG9VzjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e5a200-759c-4cbf-e361-5bd580baa650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.74      0.74      1000\n",
            "           1       0.95      0.96      0.96      1000\n",
            "           2       0.66      0.68      0.67      1000\n",
            "           3       0.76      0.81      0.78      1000\n",
            "           4       0.67      0.74      0.70      1000\n",
            "           5       0.88      0.79      0.83      1000\n",
            "           6       0.55      0.46      0.50      1000\n",
            "           7       0.83      0.89      0.85      1000\n",
            "           8       0.95      0.90      0.93      1000\n",
            "           9       0.87      0.90      0.89      1000\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.78     10000\n",
            "weighted avg       0.79      0.79      0.78     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the first 1000 rows of the test set\n",
        "test_predictions_subset = best_svm_classifier_large.predict(test_images_scaled[:subset_size_test])\n",
        "\n",
        "# Compute the classification report for the test subset\n",
        "class_report = classification_report(test_labels[:subset_size_test], test_predictions_subset)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Analysis***\n",
        "\n",
        "### ***Class 0 (T-shirt/top):***\n",
        "\n",
        "Precision: 0.76,\n",
        "Out of all instances predicted as T-shirt/top, 76% were correct.\n",
        "Recall: 0.70,\n",
        "Out of all actual T-shirt/top instances, 70% were correctly predicted.\n",
        "F1-score: 0.73,\n",
        "A balance between precision and recall for T-shirt/top.\n",
        "\n",
        "### ***Class 1 (Trouser):***\n",
        "\n",
        "Precision: 0.96,\n",
        "96% of instances predicted as Trouser were correct.\n",
        "Recall: 0.98,\n",
        "98% of actual Trouser instances were correctly predicted.\n",
        "F1-score: 0.97,\n",
        "A high balance between precision and recall for Trouser.\n",
        "\n",
        "### ***Class 2 (Pullover):***\n",
        "\n",
        "Precision: 0.64,\n",
        "64% of instances predicted as Pullover were correct.\n",
        "Recall: 0.65,\n",
        "65% of actual Pullover instances were correctly predicted.\n",
        "F1-score: 0.65,\n",
        "A balance between precision and recall for Pullover.\n",
        "\n",
        "### ***Class 3 (Dress):***\n",
        "\n",
        "Precision: 0.80,\n",
        "80% of instances predicted as Dress were correct.\n",
        "Recall: 0.85,\n",
        "85% of actual Dress instances were correctly predicted.\n",
        "F1-score: 0.82,\n",
        "A balanced measure of precision and recall for Dress.\n",
        "\n",
        "### ***Class 4 (Coat):***\n",
        "\n",
        "Precision: 0.62,\n",
        "62% of instances predicted as Coat were correct.\n",
        "Recall: 0.70,\n",
        "70% of actual Coat instances were correctly predicted.\n",
        "F1-score: 0.66,\n",
        "A balanced measure for Coat with precision and recall.\n",
        "\n",
        "### ***Class 5 (Sandal):***\n",
        "\n",
        "Precision: 0.92,\n",
        "92% of instances predicted as Sandal were correct.\n",
        "Recall: 0.82,\n",
        "82% of actual Sandal instances were correctly predicted.\n",
        "F1-score: 0.87,\n",
        "A high balance between precision and recall for Sandal.\n",
        "\n",
        "### ***Class 6 (Shirt):***\n",
        "\n",
        "Precision: 0.54,\n",
        "54% of instances predicted as Shirt were correct.\n",
        "Recall: 0.52,\n",
        "52% of actual Shirt instances were correctly predicted.\n",
        "F1-score: 0.53,\n",
        "A moderate balance between precision and recall for Shirt.\n",
        "\n",
        "### ***Class 7 (Sneaker):***\n",
        "\n",
        "Precision: 0.86,\n",
        "86% of instances predicted as Sneaker were correct.\n",
        "Recall: 0.94,\n",
        "94% of actual Sneaker instances were correctly predicted.\n",
        "F1-score: 0.90,\n",
        "A high balance between precision and recall for Sneaker.\n",
        "\n",
        "### ***Class 8 (Bag):***\n",
        "\n",
        "Precision: 0.96,\n",
        "96% of instances predicted as Bag were correct.\n",
        "Recall: 0.87,\n",
        "87% of actual Bag instances were correctly predicted.\n",
        "F1-score: 0.91,\n",
        "A high balance between precision and recall for Bag.\n",
        "\n",
        "### ***Class 9 (Ankle boot):***\n",
        "\n",
        "Precision: 0.91,\n",
        "91% of instances predicted as Ankle boot were correct.\n",
        "Recall: 0.91,\n",
        "91% of actual Ankle boot instances were correctly predicted.\n",
        "F1-score: 0.91,\n",
        "A high balance between precision and recall for Ankle boot.\n",
        "\n",
        "### ***Accuracy:***\n",
        "\n",
        "* Overall accuracy: 0.79 (79%).\n",
        "The model correctly predicted the class for 79% of instances in the test set.\n",
        "\n",
        "* Macro avg:\n",
        "Macro avg precision, recall, and F1-score: 0.80.\n",
        "The average precision, recall, and F1-score across all classes.\n",
        "\n",
        "* Weighted avg:\n",
        "Weighted avg precision, recall, and F1-score: 0.79.\n",
        "The weighted average considering the number of instances for each class."
      ],
      "metadata": {
        "id": "HUcS0lFKDaDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***SVM Classifier With HOG Feature Extraction***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8q9b7u_IIFLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skimage.feature import hog\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Function to extract HOG features from an image\n",
        "def extract_hog_features(images):\n",
        "    hog_features = []\n",
        "    for image in images:\n",
        "        # Calculate HOG features and flatten the result\n",
        "        features, hog_image = hog(image, visualize=True, block_norm='L2-Hys')\n",
        "        hog_features.append(features)\n",
        "    return np.array(hog_features)\n",
        "\n",
        "# Extract HOG features for training images\n",
        "train_images_hog = extract_hog_features(train_images)\n",
        "\n",
        "# Extract HOG features for test images\n",
        "test_images_hog = extract_hog_features(test_images)\n",
        "\n",
        "# Flatten the HOG features\n",
        "train_images_hog_flat = train_images_hog.reshape(train_images_hog.shape[0], -1)\n",
        "test_images_hog_flat = test_images_hog.reshape(test_images_hog.shape[0], -1)\n",
        "\n",
        "# Normalize pixel values to a common scale (e.g., 0 to 1)\n",
        "scaler_hog = StandardScaler()\n",
        "train_images_hog_scaled = scaler_hog.fit_transform(train_images_hog_flat.astype(float))\n",
        "test_images_hog_scaled = scaler_hog.transform(test_images_hog_flat.astype(float))\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_images_hog_final, val_images_hog_final, train_labels_final, val_labels_final = \\\n",
        "    train_test_split(train_images_hog_scaled, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier for HOG features\n",
        "svm_classifier_hog = SVC(C=1.0)\n",
        "\n",
        "# Training Time before\n",
        "start_time_before_tuning = time.time()\n",
        "svm_classifier_hog.fit(train_images_hog_final, train_labels_final)\n",
        "training_time_before_tuning = time.time() - start_time_before_tuning\n",
        "print(f\"Training Time: {training_time_before_tuning:.2f} seconds\")\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions_before_tuning = svm_classifier_hog.predict(val_images_hog_final)\n",
        "\n",
        "# Evaluate accuracy on the validation set\n",
        "accuracy_before_tuning = accuracy_score(val_labels_final, val_predictions_before_tuning)\n",
        "print(f\"Validation Accuracy: {accuracy_before_tuning * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8q5Xv4HIUoG",
        "outputId": "91229229-64bb-4895-a0a6-97792c033d09"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 1.73 seconds\n",
            "Validation Accuracy: 82.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-Validation Scores for HOG features\n",
        "cross_val_scores_hog = cross_val_score(svm_classifier_hog, train_images_hog_scaled, train_labels, cv=5, n_jobs=-1)\n",
        "print(f\"Cross-Validation Scores for HOG Features: {np.mean(cross_val_scores_hog) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsLnJlTlM928",
        "outputId": "2fad933f-8336-46e9-d4c5-c63b5c4fe1f3"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for HOG Features: 82.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_classifier_hog.fit(train_images_hog_scaled, train_labels)\n",
        "\n",
        "# Make predictions on the test set using HOG features\n",
        "test_predictions_hog = svm_classifier_hog.predict(test_images_hog_scaled)\n",
        "\n",
        "# Compute the confusion matrix for HOG features\n",
        "conf_matrix_hog = confusion_matrix(test_labels, test_predictions_hog)\n",
        "print(\"Confusion Matrix for HOG Features:\")\n",
        "print(conf_matrix_hog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa_9gXT1NCbJ",
        "outputId": "eb1d96fb-8d88-4ca5-fba5-bb8a4ebd85a9"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for HOG Features:\n",
            "[[819   4  28  42   7   1  86   0  13   0]\n",
            " [  2 956   4  30   1   0   6   0   1   0]\n",
            " [ 19   0 707   8 135   0 124   0   7   0]\n",
            " [ 25  11   7 881  41   0  34   0   1   0]\n",
            " [  1   1  63  36 760   0 136   0   3   0]\n",
            " [  0   0   0   1   0 911   0  68   1  19]\n",
            " [188   4  93  42 115   0 550   0   8   0]\n",
            " [  0   0   0   0   0  46   0 904   0  50]\n",
            " [  5   1   2   3   3   5  11   1 968   1]\n",
            " [  0   0   0   0   0  12   0  33   1 954]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the classification report for HOG features\n",
        "class_report_hog = classification_report(test_labels, test_predictions_hog)\n",
        "print(\"Classification Report for HOG Features:\")\n",
        "print(class_report_hog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HaXkPuoNGAo",
        "outputId": "244ca4c8-e340-4563-d7ac-67aef6dd7c58"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for HOG Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.82      0.80      1000\n",
            "           1       0.98      0.96      0.97      1000\n",
            "           2       0.78      0.71      0.74      1000\n",
            "           3       0.84      0.88      0.86      1000\n",
            "           4       0.72      0.76      0.74      1000\n",
            "           5       0.93      0.91      0.92      1000\n",
            "           6       0.58      0.55      0.56      1000\n",
            "           7       0.90      0.90      0.90      1000\n",
            "           8       0.97      0.97      0.97      1000\n",
            "           9       0.93      0.95      0.94      1000\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Our Overall accuracy has been improved by using HOG.***"
      ],
      "metadata": {
        "id": "SXqep1lbX7DC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# ***SVM with SIFT***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xLVV1jZoZBdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# Function to extract SIFT features from an image\n",
        "def extract_sift_features(images):\n",
        "    sift = cv2.SIFT_create()\n",
        "    sift_features = []\n",
        "\n",
        "    for image in images:\n",
        "        # Ensure the image is in uint8 format\n",
        "        image = (image * 255).astype(np.uint8)\n",
        "\n",
        "        keypoints, descriptors = sift.detectAndCompute(image, None)\n",
        "\n",
        "        # Ensure descriptors is not None\n",
        "        if descriptors is not None:\n",
        "            # Flatten and zero-pad descriptors to a fixed length (e.g., 128)\n",
        "            flattened_descriptors = descriptors.flatten()[:128]\n",
        "            zero_padding = np.zeros(128 - len(flattened_descriptors))\n",
        "            sift_features.append(np.concatenate([flattened_descriptors, zero_padding]))\n",
        "        else:\n",
        "            sift_features.append(np.zeros(128))\n",
        "\n",
        "    return np.array(sift_features)\n",
        "\n",
        "# Extract SIFT features for training images\n",
        "train_images_sift = extract_sift_features(train_images)\n",
        "\n",
        "# Extract SIFT features for test images\n",
        "test_images_sift = extract_sift_features(test_images)\n",
        "\n",
        "# Normalize pixel values to a common scale (e.g., 0 to 1)\n",
        "scaler_sift = StandardScaler()\n",
        "train_images_sift_scaled = scaler_sift.fit_transform(train_images_sift.astype(float))\n",
        "test_images_sift_scaled = scaler_sift.transform(test_images_sift.astype(float))\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_images_sift_final, val_images_sift_final, train_labels_final, val_labels_final = \\\n",
        "    train_test_split(train_images_sift_scaled, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier for SIFT features\n",
        "svm_classifier_sift = SVC(C=1.0)\n",
        "\n",
        "# Training Time\n",
        "start_time_before_tuning_sift = time.time()\n",
        "svm_classifier_sift.fit(train_images_sift_final, train_labels_final)\n",
        "training_time_before_tuning_sift = time.time() - start_time_before_tuning_sift\n",
        "print(f\"Training Time: {training_time_before_tuning_sift:.2f} seconds\")\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions_before_tuning_sift = svm_classifier_sift.predict(val_images_sift_final)\n",
        "\n",
        "# Evaluate accuracy on the validation set\n",
        "accuracy_before_tuning_sift = accuracy_score(val_labels_final, val_predictions_before_tuning_sift)\n",
        "print(f\"Validation Accuracy: {accuracy_before_tuning_sift * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzlQ5jDeZH_n",
        "outputId": "eab3e1f0-7218-4cb1-e17d-30fd9e6abaa1"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time before Hyperparameter Tuning (SIFT): 9.96 seconds\n",
            "Validation Accuracy before Hyperparameter Tuning (SIFT): 36.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-Validation Scores for SIFT features\n",
        "cross_val_scores_sift = cross_val_score(svm_classifier_sift, train_images_sift_scaled, train_labels, cv=5, n_jobs=-1)\n",
        "print(f\"Cross-Validation Scores for SIFT Features: {np.mean(cross_val_scores_sift) * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuwZYJNDfHYJ",
        "outputId": "63be3764-2f64-43ab-fede-f43bb7e11f49"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for SIFT Features: 36.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit SVM classifier on SIFT features\n",
        "svm_classifier_sift.fit(train_images_sift_scaled, train_labels)\n",
        "\n",
        "# Make predictions on the test set using SIFT features\n",
        "test_predictions_sift = svm_classifier_sift.predict(test_images_sift_scaled)\n",
        "\n",
        "# Compute the confusion matrix for SIFT features\n",
        "conf_matrix_sift = confusion_matrix(test_labels, test_predictions_sift)\n",
        "print(\"Confusion Matrix for SIFT Features:\")\n",
        "print(conf_matrix_sift)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkNBm29RfPk3",
        "outputId": "2acf8865-ea3d-4d4a-ad3b-50d00a4e38ab"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for SIFT Features:\n",
            "[[299  45  46 226  31  48 104  18 127  56]\n",
            " [ 16 580  21 205  14  58  10  38  37  21]\n",
            " [ 40  29 235 239  91  19 195  13  98  41]\n",
            " [ 71 160  29 421  33  49  67  59  66  45]\n",
            " [ 57  44  84 254 182  36 169  15 120  39]\n",
            " [ 29  70  10  73  16 375  20 186  89 132]\n",
            " [126  47  61 222  74  31 282  17 101  39]\n",
            " [ 21  62   3 134   8  90  12 521  33 116]\n",
            " [ 51  45  68 202  48  84  62  34 345  61]\n",
            " [ 26  15  14 118  18  89  14  79  82 545]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the classification report for SIFT features\n",
        "class_report_sift = classification_report(test_labels, test_predictions_sift)\n",
        "print(\"Classification Report for SIFT Features:\")\n",
        "print(class_report_sift)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZeLlktkfbMf",
        "outputId": "009527a4-c624-4923-a739-e2bd42a9b26d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for SIFT Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.30      0.34      1000\n",
            "           1       0.53      0.58      0.55      1000\n",
            "           2       0.41      0.23      0.30      1000\n",
            "           3       0.20      0.42      0.27      1000\n",
            "           4       0.35      0.18      0.24      1000\n",
            "           5       0.43      0.38      0.40      1000\n",
            "           6       0.30      0.28      0.29      1000\n",
            "           7       0.53      0.52      0.53      1000\n",
            "           8       0.31      0.34      0.33      1000\n",
            "           9       0.50      0.55      0.52      1000\n",
            "\n",
            "    accuracy                           0.38     10000\n",
            "   macro avg       0.40      0.38      0.38     10000\n",
            "weighted avg       0.40      0.38      0.38     10000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}